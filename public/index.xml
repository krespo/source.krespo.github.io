<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>나는 개발자</title>
    <link>https://krespo.github.io/</link>
    <description>Recent content on 나는 개발자</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-KR</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Tue, 03 Mar 2020 16:19:21 +0900</lastBuildDate>
    
	<atom:link href="https://krespo.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Kudu]Kudu와 Presto 그리고 unix_timestamp에 대해 이해하기</title>
      <link>https://krespo.github.io/posts/kudu/presto-kudu-datetime/</link>
      <pubDate>Tue, 03 Mar 2020 16:19:21 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/presto-kudu-datetime/</guid>
      <description>Kudu 공식 문서에도 나와있지만 Kudu에서 주로 사용하는 쿼리엔진은 Impala나 Hive다. 하지만 필자는 이미 사용하고 있는 Presto 클러스터가 있어 Presto-Kudu Connector 를 이용하</description>
    </item>
    
    <item>
      <title>[Airflow] Multi Server Cluster 환경에서 dag 파일은 모든 서버에 배포해야할까?</title>
      <link>https://krespo.github.io/posts/airflow/dag_deployment/</link>
      <pubDate>Mon, 24 Feb 2020 16:47:18 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/dag_deployment/</guid>
      <description>오늘은 Multi Server Cluster 환경에서 dag를 배포하는것에 대해 이야기를 해보려고한다. 얼마전에 블로그 댓글을 통해 이런 문의가 왔었다. Master 역할을 하는 서버에만 dag를 배포</description>
    </item>
    
    <item>
      <title>[Airflow] Local 개발환경 설정(2)_Dag 개발</title>
      <link>https://krespo.github.io/posts/airflow/develop-environment-with-dags/</link>
      <pubDate>Tue, 11 Feb 2020 13:29:34 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/develop-environment-with-dags/</guid>
      <description>앞서 Local 개발환경 설정(1)_설치를 통해 로컬에 Airflow를 설치를 해보았다. 이번에는 로컬에 설치된 Airflow를 이용하여 dag를 개발할 수 있는 환</description>
    </item>
    
    <item>
      <title>[Sqoop] Parameter &#39;directory&#39; is not a directory 에러 해결하기</title>
      <link>https://krespo.github.io/posts/sqoop/is-not-a-directory-error/</link>
      <pubDate>Mon, 10 Feb 2020 17:33:42 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/sqoop/is-not-a-directory-error/</guid>
      <description>.bash_profile 이나 ${SQOOP_HOME}/conf/sqoop_env.sh에 HADOOP_MAPRED_HOME 환경변수를 지정했음에도 계속 아래와 같이 HADOOP_MAPRED_HO</description>
    </item>
    
    <item>
      <title>[Airflow] Local 개발환경 설정(1)_설치</title>
      <link>https://krespo.github.io/posts/airflow/develop-environment/</link>
      <pubDate>Wed, 05 Feb 2020 16:53:19 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/develop-environment/</guid>
      <description>로컬에서 airflow dag를 생성하거나, 커스텀 오퍼레이터를 생성하기 위해서 로컬에 airflow를 세팅하고, dag를 개발하는 환경을 구축해 보고자 한다. 요구사</description>
    </item>
    
    <item>
      <title>[Airflow] BashOperator 확장을 통한 Spark Custom Operator</title>
      <link>https://krespo.github.io/posts/airflow/spark-custom-operator/</link>
      <pubDate>Wed, 05 Feb 2020 11:06:09 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/spark-custom-operator/</guid>
      <description>이전 포스팅을 통해 SparkSubmitOperator을 사용해보았다. 하지만 포스팅 말미에도 적어놓았지만 SparkSubmitOperator</description>
    </item>
    
    <item>
      <title>[기타] Chrome NET::ERR_CERT_REVOKED 해결방법</title>
      <link>https://krespo.github.io/posts/etc/chrome_err_cert_revoked_error/</link>
      <pubDate>Fri, 31 Jan 2020 16:56:58 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/etc/chrome_err_cert_revoked_error/</guid>
      <description>Self-signed certificate 인증서를 생성하여 HTTPS를 적용하게 되면 위의 이미지처럼 크롬에서 NET::ERR_CERT_REVOKED 에러가 발생하며 HTTPS 접근이 불가능하다. (Safari나 Firefox에서는 접</description>
    </item>
    
    <item>
      <title>[Kudu] 시간 기준의 Range Partition 시 주의점(timezone, UTC)</title>
      <link>https://krespo.github.io/posts/kudu/range-partition/</link>
      <pubDate>Tue, 14 Jan 2020 13:13:56 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/range-partition/</guid>
      <description>Kudu는 시간 컬럼을 저장할 때 unixtime_micros를 이용해서 저장한다. 만약 이 컬럼을 통해 연도별,월별,일별 등 시간으로 Range Partitio</description>
    </item>
    
    <item>
      <title>[Nifi]Could Not Generate Extensions Documentation 에러 해결 방법</title>
      <link>https://krespo.github.io/posts/nifi/could-not-generate-extensions-documentation/</link>
      <pubDate>Thu, 02 Jan 2020 11:01:41 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/nifi/could-not-generate-extensions-documentation/</guid>
      <description>커스텀 프로세서 생성 후 mvn clean package를 통해 .nar파일을 생성하는데, 아래와 같은 에러가 발생했다. [ERROR] Could not generate extensions&#39; documentation org.apache.maven.plugin.MojoExecutionException: Failed to create Extension Documentation at org.apache.nifi.NarMojo.generateDocumentation (NarMojo.java:596) at org.apache.nifi.NarMojo.execute (NarMojo.java:499) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137) at</description>
    </item>
    
    <item>
      <title>[Java] invalid source release 에러 해결</title>
      <link>https://krespo.github.io/posts/java/invalid-source-release-error/</link>
      <pubDate>Thu, 02 Jan 2020 10:21:11 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/java/invalid-source-release-error/</guid>
      <description>Error:java: invalid source release: 11 프로젝트를 진행하다보면 위와같은 에러를 보일때가 있는데, Intellij의 설정을 수정하여 해결할 수 있다. 1. Language Level 수정 Intellij에서 File</description>
    </item>
    
    <item>
      <title>[Nifi] Custom Processor 생성 및 테스트 With Docker</title>
      <link>https://krespo.github.io/posts/nifi/create-custom-processor/</link>
      <pubDate>Wed, 18 Dec 2019 20:17:52 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/nifi/create-custom-processor/</guid>
      <description>nifi에 커스텀 프로세서를 등록할 일이 생겼는데, 커스텀 프로세서를 빌드한 후 테스트 하기가 까다로워 도커를 이용하여 로컬에 환경을 구축하고 간단하게 테스트 하</description>
    </item>
    
    <item>
      <title>[Kafka] 파티션 Skew, Leader Skew 그리고 Reassign Partition</title>
      <link>https://krespo.github.io/posts/kafka/skew-reassign-partition/</link>
      <pubDate>Wed, 11 Dec 2019 16:16:49 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kafka/skew-reassign-partition/</guid>
      <description>kafka-manager에서 카프카를 운영하다보면 Skewed 혹은 Leader Skewed가 true가 된 것을 종종 볼수 있다. 그럼 Skew는 무엇일까? Skew는 카프</description>
    </item>
    
    <item>
      <title>[Kudu] 4. 인코딩과 압축</title>
      <link>https://krespo.github.io/posts/kudu/encoding-compression/</link>
      <pubDate>Tue, 10 Dec 2019 18:22:25 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/encoding-compression/</guid>
      <description>Kudu에서는 컬럼의 인코딩과 압축을 통해 저장 데이터의 사이즈를 줄여, 디스크 공간을 효율적으로 사용할 수 있도록 하고 있다. 1. 인코딩 인코딩은 테이블 생성 시 컬</description>
    </item>
    
    <item>
      <title>[Kafka Manager] 1.Installation</title>
      <link>https://krespo.github.io/posts/kafka-manager/install-kafka-manager/</link>
      <pubDate>Tue, 10 Dec 2019 14:31:31 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kafka-manager/install-kafka-manager/</guid>
      <description>yahoo에서 만든 kafka-manager를 이용하면 카프카 운영을 위한 다양한 일들을 Web UI기반으로 처리할 수 있다. 설치 ## https://github.com/yahoo/kafka-manager/releases 에서 원하는 버전을 확인하</description>
    </item>
    
    <item>
      <title>[Kudu] 3. Source Build를 이용한 설치</title>
      <link>https://krespo.github.io/posts/kudu/install_kudu/</link>
      <pubDate>Wed, 04 Dec 2019 16:52:07 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/install_kudu/</guid>
      <description>kudu를 설치하는 방법은 cloudera repository를 이용하여 설치하는 방법이 있고, source build를 통해 설치하는 방법이 있는데, cloudera 버전은 라이센스 관련 이슈</description>
    </item>
    
    <item>
      <title>[Kudu] 2. Write And Compaction</title>
      <link>https://krespo.github.io/posts/kudu/read-write-compaction/</link>
      <pubDate>Mon, 02 Dec 2019 18:41:12 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/read-write-compaction/</guid>
      <description>본 포스팅은 아래의 출처의 정보들을 조합하여 나름의 구성을 진행하였다. 잘못 이해하고 있거나, 문제가 있는 부분이 있을수 있음을 사전에 명시하고 시작하도록 하겠다</description>
    </item>
    
    <item>
      <title>[Kudu] 1. 소개 및 아키텍쳐</title>
      <link>https://krespo.github.io/posts/kudu/introducing_apache_kudu/</link>
      <pubDate>Mon, 02 Dec 2019 11:19:53 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/kudu/introducing_apache_kudu/</guid>
      <description>Apache Kudu 는 Columnar Storage로서, 실시간/대용량 데이터 분석이 가능한 저장 엔진이다. 여기에 Impala, Spark를 이용하여 쉽고 빠른 데이터 분석이 가능한 특징이 있다.</description>
    </item>
    
    <item>
      <title>[Airflow] SparkSubmitOperator를 이용한 spark 실행</title>
      <link>https://krespo.github.io/posts/airflow/spark-submit-and-airflow/</link>
      <pubDate>Tue, 12 Nov 2019 13:23:33 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/spark-submit-and-airflow/</guid>
      <description>Airflow에서는 다양한 Operator를 지원하는데 그 중 Spark을 실행하기 위한 SparkSubmitOperator 라는 것이 존재한다. 이번에는 SparkSubmitOper</description>
    </item>
    
    <item>
      <title>[Airflow] macOS catalina에서 hostname does not match this instance&#39;s hostname 해결하기</title>
      <link>https://krespo.github.io/posts/airflow/hostname-error/</link>
      <pubDate>Mon, 11 Nov 2019 16:34:10 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/hostname-error/</guid>
      <description>얼마전 macOS Catalina버전으로 업그레이드 되면서 로컬에서 airflow가 정상적으로 동작하지 않는 문제가 생겼다. The recorded hostname [1m1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa[0m does not match this instance&amp;rsquo;s hostname [1m1.0.0.127.in-addr.arpa 위의 에러 메</description>
    </item>
    
    <item>
      <title>Mysql 바이너리로그 끄고 켜기</title>
      <link>https://krespo.github.io/posts/mysql/on-off-bin-log/</link>
      <pubDate>Thu, 07 Nov 2019 13:50:51 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/mysql/on-off-bin-log/</guid>
      <description>바이너리 로그는 master-slave 구성을 하거나, CDC를 할 때 사용하는데, 상황에 따라서 enable/disable 해야할 이슈가 있어 기록차원에서 남겨본다. 1.bin-log on $ vi /etc/my.cfg [mysqld] log-data=/data1/mysql/,ysql-bin $ sudo service mysql restart 2.bin-log off $ vi /etc/my.cfg</description>
    </item>
    
  </channel>
</rss>