<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>airflow on 나는 개발자</title>
    <link>https://krespo.github.io/tags/airflow/</link>
    <description>Recent content in airflow on 나는 개발자</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-KR</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Mon, 24 Feb 2020 16:47:18 +0900</lastBuildDate>
    
	<atom:link href="https://krespo.github.io/tags/airflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[Airflow] Multi Server Cluster 환경에서 dag 파일은 모든 서버에 배포해야할까?</title>
      <link>https://krespo.github.io/posts/airflow/dag_deployment/</link>
      <pubDate>Mon, 24 Feb 2020 16:47:18 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/dag_deployment/</guid>
      <description>오늘은 Multi Server Cluster 환경에서 dag를 배포하는것에 대해 이야기를 해보려고한다. 얼마전에 블로그 댓글을 통해 이런 문의가 왔었다. Master 역할을 하는 서버에만 dag를 배포</description>
    </item>
    
    <item>
      <title>[Airflow] Local 개발환경 설정(2)_Dag 개발</title>
      <link>https://krespo.github.io/posts/airflow/develop-environment-with-dags/</link>
      <pubDate>Tue, 11 Feb 2020 13:29:34 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/develop-environment-with-dags/</guid>
      <description>앞서 Local 개발환경 설정(1)_설치를 통해 로컬에 Airflow를 설치를 해보았다. 이번에는 로컬에 설치된 Airflow를 이용하여 dag를 개발할 수 있는 환</description>
    </item>
    
    <item>
      <title>[Airflow] Local 개발환경 설정(1)_설치</title>
      <link>https://krespo.github.io/posts/airflow/develop-environment/</link>
      <pubDate>Wed, 05 Feb 2020 16:53:19 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/develop-environment/</guid>
      <description>로컬에서 airflow dag를 생성하거나, 커스텀 오퍼레이터를 생성하기 위해서 로컬에 airflow를 세팅하고, dag를 개발하는 환경을 구축해 보고자 한다. 요구사</description>
    </item>
    
    <item>
      <title>[Airflow] BashOperator 확장을 통한 Spark Custom Operator</title>
      <link>https://krespo.github.io/posts/airflow/spark-custom-operator/</link>
      <pubDate>Wed, 05 Feb 2020 11:06:09 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/spark-custom-operator/</guid>
      <description>이전 포스팅을 통해 SparkSubmitOperator을 사용해보았다. 하지만 포스팅 말미에도 적어놓았지만 SparkSubmitOperator</description>
    </item>
    
    <item>
      <title>[Airflow] SparkSubmitOperator를 이용한 spark 실행</title>
      <link>https://krespo.github.io/posts/airflow/spark-submit-and-airflow/</link>
      <pubDate>Tue, 12 Nov 2019 13:23:33 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/spark-submit-and-airflow/</guid>
      <description>Airflow에서는 다양한 Operator를 지원하는데 그 중 Spark을 실행하기 위한 SparkSubmitOperator 라는 것이 존재한다. 이번에는 SparkSubmitOper</description>
    </item>
    
    <item>
      <title>[Airflow] macOS catalina에서 hostname does not match this instance&#39;s hostname 해결하기</title>
      <link>https://krespo.github.io/posts/airflow/hostname-error/</link>
      <pubDate>Mon, 11 Nov 2019 16:34:10 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/hostname-error/</guid>
      <description>얼마전 macOS Catalina버전으로 업그레이드 되면서 로컬에서 airflow가 정상적으로 동작하지 않는 문제가 생겼다. The recorded hostname [1m1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa[0m does not match this instance&amp;rsquo;s hostname [1m1.0.0.127.in-addr.arpa 위의 에러 메</description>
    </item>
    
    <item>
      <title>[Airflow] Scheduler SPOF(Single Point Of Failure) 제거하기</title>
      <link>https://krespo.github.io/posts/airflow/airflow-scheduler-failover/</link>
      <pubDate>Mon, 04 Nov 2019 18:48:06 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/airflow-scheduler-failover/</guid>
      <description>위의 그림은 celery executor를 이용한 여러대의 워커로 구성한 아키텍쳐이다. 이중 scheduler는 DB에서 스케줄 정보를 가져와 redis의 pub/</description>
    </item>
    
    <item>
      <title>[Airflow] 커버로스 설정 및 hive 연결</title>
      <link>https://krespo.github.io/posts/airflow/kerberos-configuration/</link>
      <pubDate>Mon, 04 Nov 2019 16:05:44 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/kerberos-configuration/</guid>
      <description>airflow를 이용하여 kerberos 인증이 적용된 데이터소스(ex - hadoop)에 접근하려면 커버로스 설정을 airflow에 적용해야 한다. 아래의 예제는 kerberos</description>
    </item>
    
    <item>
      <title>[Airflow] 설치</title>
      <link>https://krespo.github.io/posts/airflow/1_airflow_install/</link>
      <pubDate>Mon, 04 Nov 2019 11:34:19 +0900</pubDate>
      
      <guid>https://krespo.github.io/posts/airflow/1_airflow_install/</guid>
      <description>설치 환경 CentOS 7.7 airflow 1.10.5 airflow는 단일 서버에서 설치하는 방법외에 python celery모듈을 이용하여 webserver와 worker서버를 분리 할수 있다.</description>
    </item>
    
  </channel>
</rss>